{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57c1c2e0",
   "metadata": {},
   "source": [
    "# Advanced Deep Learning Project - Part 2\n",
    "## Group 8\n",
    "### Yael Heger, Hila Baram, Ella Tamir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d240e48b",
   "metadata": {},
   "source": [
    "### Imports: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d91896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch:\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.quantization as quantization\n",
    "\n",
    "# Transformers:\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AlbertTokenizer, AlbertModel\n",
    "\n",
    "# SkLearn:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, plot_roc_curve, accuracy_score, auc, f1_score, precision_score, recall_score  \n",
    "\n",
    "# Matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Others:\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import string\n",
    "import nltk\n",
    "from nltk import corpus\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c7454d",
   "metadata": {},
   "source": [
    " Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae88c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the location of the data localy.\n",
    "\n",
    "data_neg = 'C:/Users/user/Documents/Advanced Deep Learning/Group8/train_data (1)/train/neg'\n",
    "data_pos = 'C:/Users/user/Documents/Advanced Deep Learning/Group8/train_data (1)/train/pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c4cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_to_list(data_dir):\n",
    "    # The function receives the path of the files.\n",
    "    # The function returns a list containing the files paths and a list containing the data.\n",
    "    \n",
    "    txt_files = []    # A list to save the opened review files.\n",
    "    file_paths = []\n",
    "    for (roots, dirs, files) in os.walk(data_dir): # Reading every file in every folder.     \n",
    "        for obj in files:  \n",
    "            file = open(roots + '/'+ obj, 'r', encoding = 'utf-8')\n",
    "            file_paths.append(roots + '/'+ obj)\n",
    "            cont = file.read()\n",
    "            txt_files.append(cont)\n",
    "            file.close()\n",
    "    return file_paths, txt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32091be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_files, neg_rev = read_data_to_list(data_neg)   # Negative reviews\n",
    "pos_files, pos_rev = read_data_to_list(data_pos)   # Positive reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69023c2",
   "metadata": {},
   "source": [
    "Converting to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e24a9853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18745</th>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18746</th>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18747</th>\n",
       "      <td>I am amazed at how this movie(and most others ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18748</th>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18749</th>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18750 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review\n",
       "0      Bromwell High is a cartoon comedy. It ran at t...\n",
       "1      Homelessness (or Houselessness as George Carli...\n",
       "2      Brilliant over-acting by Lesley Ann Warren. Be...\n",
       "3      This is easily the most underrated film inn th...\n",
       "4      This is not the typical Mel Brooks film. It wa...\n",
       "...                                                  ...\n",
       "18745  Seeing as the vote average was pretty low, and...\n",
       "18746  The plot had some wretched, unbelievable twist...\n",
       "18747  I am amazed at how this movie(and most others ...\n",
       "18748  A Christmas Together actually came before my t...\n",
       "18749  Working-class romantic drama from director Mar...\n",
       "\n",
       "[18750 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_pd = pd.DataFrame(pos_rev, columns=[\"Review\"])\n",
    "pos_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf8962a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pd = pd.DataFrame(neg_rev, columns=[\"Review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3fc35",
   "metadata": {},
   "source": [
    "## Pre- Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152da75",
   "metadata": {},
   "source": [
    "First, we are cleaning the data from punctuation and converting all letters to lower-case, seperatley for the positive and negative reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "701fe324",
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # The function receives the text to clean.\n",
    "    # The function clears punctuation marks and other non-alphabetic characters and converts all the text to lower case.\n",
    "    # The function returns the cleaned data.\n",
    "    brs = [\"br\", \"<br>\", \"</br>\", \" br\", \"br \"]   # To clean all the different shapes that there's in the data. \n",
    "    punctuationfree=\"\".join([i for i in text if i not in brs])\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7dc5328",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pd[\"Review\"] = pos_pd[\"Review\"].apply(lambda x:remove_punctuation(x))\n",
    "neg_pd[\"Review\"] = neg_pd[\"Review\"].apply(lambda x:remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b43d1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pd['Review'] = pos_pd['Review'].apply(lambda x: x.lower())\n",
    "neg_pd['Review'] = neg_pd['Review'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c0f4d3",
   "metadata": {},
   "source": [
    "Second, we will split the sentences to a list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1577c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(text):\n",
    "    tokens = re.split(' ',text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbda5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pd[\"Review\"] = pos_pd[\"Review\"].apply(lambda x: split(x))\n",
    "neg_pd[\"Review\"] = neg_pd[\"Review\"].apply(lambda x: split(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebebe3",
   "metadata": {},
   "source": [
    "### removing stop words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefcb4f4",
   "metadata": {},
   "source": [
    "In order to remove stopwords, we are using the stopwords dictionary from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11876531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "warnings.filterwarnings('ignore')\n",
    "def remove_stopwords(text):\n",
    "    stopwords = corpus.stopwords.words('english')\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8319725",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pd[\"Review\"] = pos_pd[\"Review\"].apply(lambda x:remove_stopwords(x))\n",
    "neg_pd[\"Review\"] = neg_pd[\"Review\"].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d69ab6",
   "metadata": {},
   "source": [
    "## Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d1b0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_and_count_data(data):\n",
    "    # The function receives data and returns its length and a dictionary that contains the number of times each word appears.\n",
    "    lengths_list = []\n",
    "    words_dict = {}\n",
    "    for i in range(len(data)):\n",
    "        lengths_list.append(len(data[i]))\n",
    "        split_sentence = data[i]\n",
    "        for word in split_sentence:\n",
    "                if word not in words_dict.keys(): # If new word.\n",
    "                    words_dict[word] = 1\n",
    "                else:\n",
    "                    words_dict[word] +=1 # Appears more than once. \n",
    "    return lengths_list, words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25565a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lengths, pos_dict = length_and_count_data(pos_pd[\"Review\"])\n",
    "neg_lengths, neg_dict = length_and_count_data(neg_pd[\"Review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def9d893",
   "metadata": {},
   "source": [
    "### Length histogram for each review type "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e05584f",
   "metadata": {},
   "source": [
    "In these histograms we can see the expected value of the sentences length, seperated to negative and positive reviews.\n",
    "\n",
    "y axis - number of words for each length.\n",
    "\n",
    "x axis - lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3a6fd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=[15,5])\n",
    "ax[0].hist(pos_lengths, bins = 400, color='forestgreen')\n",
    "ax[0].set_title(\"Positive reviews length\",{'fontsize':15})\n",
    "ax[1].hist(neg_lengths, bins = 400, color = \"crimson\")\n",
    "ax[1].set_title(\"Negative reviews length\",{'fontsize':15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed008d73",
   "metadata": {},
   "source": [
    "### Most Common words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506cc1a",
   "metadata": {},
   "source": [
    "Now we will check the most common words for each type without removing words that are common in both types of reviews\n",
    "\n",
    "y axis - number of appearences.\n",
    "\n",
    "x axis - word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b30b9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_pos = sorted(pos_dict.items(), key=lambda k_v: k_v[1], reverse=True)[:15]\n",
    "mc_neg = sorted(neg_dict.items(), key=lambda k_v: k_v[1], reverse=True)[:15]\n",
    "\n",
    "# Draw the bar chart\n",
    "def draw_words_hist(mc_pos, mc_neg):\n",
    "    mc_pos = dict(mc_pos)\n",
    "    names_pos = list(mc_pos.keys())\n",
    "    values_pos = list(mc_pos.values())\n",
    "\n",
    "    mc_neg = dict(mc_neg)\n",
    "    names_neg = list(mc_neg.keys())\n",
    "    values_neg = list(mc_neg.values())\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=[25,5])\n",
    "    ax[0].bar(range(len(mc_pos)),values_pos,tick_label=names_pos, color = \"forestgreen\")\n",
    "    ax[0].set_title(\"Positive\",{'fontsize':20})\n",
    "    ax[1].bar(range(len(mc_neg)),values_neg,tick_label=names_neg, color = \"crimson\")\n",
    "    ax[1].set_title(\"Negative\",{'fontsize':20})\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5db171a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_words_hist(mc_pos, mc_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a8e9ba",
   "metadata": {},
   "source": [
    "Next we will remove non unique words- if a word is in the top 100 most common words for negative and positive data, we will remove it because it has no contribution to the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9b22b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pos = sorted(pos_dict.items(), key=lambda k_v: k_v[1], reverse=True)\n",
    "dict_neg = sorted(neg_dict.items(), key=lambda k_v: k_v[1], reverse=True)\n",
    "word_pos_top_100 = [x[0] for x in dict_pos[:100]] \n",
    "word_neg_top_100 = [x[0] for x in dict_neg[:100]] \n",
    "count = 0\n",
    "removed_words = []\n",
    "flag = True\n",
    "while count < 100 and flag:\n",
    "    word = word_pos_top_100[count]\n",
    "    if word in word_neg_top_100:\n",
    "        if count == len(word_pos_top_100)-1:\n",
    "            flag = False\n",
    "            \n",
    "        ind_pos = word_pos_top_100.index(word)\n",
    "        dict_pos.pop(ind_pos)\n",
    "        word_pos_top_100.pop(ind_pos)\n",
    "        \n",
    "        ind_neg = word_neg_top_100.index(word)\n",
    "        dict_neg.pop(ind_neg)\n",
    "        word_neg_top_100.pop(ind_neg)\n",
    "        \n",
    "        removed_words.append(word)\n",
    "\n",
    "    else:\n",
    "        count += 1\n",
    "        \n",
    "\n",
    "top_100_pos = dict_pos[:15]\n",
    "top_100_neg = dict_neg[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89571b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of deleted words:  78\n",
      "Deleted words:\n",
      "['br', 'film', 'movie', 'one', '', 'like', 'good', 'great', 'story', 'time', 'see', 'well', 'also', 'really', 'would', 'even', 'much', 'first', 'people', 'films', 'love', 'best', 'get', 'way', 'life', 'many', 'characters', 'think', 'movies', 'made', 'two', 'seen', 'dont', 'character', 'show', 'watch', 'still', 'little', 'make', 'never', 'could', 'man', 'know', 'ever', 'end', 'scene', 'real', 'say', 'back', 'scenes', 'makes', 'acting', 'go', 'better', 'though', 'plot', 'find', 'work', 'lot', 'something', 'another', 'old', 'part', 'actors', 'every', 'funny', 'im', 'watching', 'doesnt', 'look', 'bad', 'things', 'going', 'actually', 'director', 'didnt', 'thing', 'around']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of deleted words: \", len(removed_words))\n",
    "print(\"Deleted words:\")\n",
    "print(removed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66a755af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_common_words(text):\n",
    "    output = [i for i in text if i not in removed_words]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19dcadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pd[\"Review\"] = pos_pd[\"Review\"].apply(lambda x:remove_common_words(x))\n",
    "neg_pd[\"Review\"] = neg_pd[\"Review\"].apply(lambda x:remove_common_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ebbc1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_words_hist(top_100_pos, top_100_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0006a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding spaces\n",
    "pos_pd[\"Review\"] = pos_pd[\"Review\"].apply(lambda x:\" \".join(x))\n",
    "neg_pd[\"Review\"] = neg_pd[\"Review\"].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7512e6c",
   "metadata": {},
   "source": [
    "## Models & Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b629645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running on GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ca86b",
   "metadata": {},
   "source": [
    "split the data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27f6d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pd['Labels'] = 1\n",
    "neg_pd['Labels'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80ffc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([pos_pd[\"Review\"], neg_pd[\"Review\"]])\n",
    "labels = pd.concat([pos_pd[\"Labels\"], neg_pd[\"Labels\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d45ad217",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test ,y_train ,y_test = train_test_split(data, labels, test_size=0.25, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "252e7c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(list(zip(X_train, y_train)), columns =['text','labels'])\n",
    "test_df = pd.DataFrame(list(zip(X_test, y_test)), columns =['text','labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e9fee",
   "metadata": {},
   "source": [
    "### Defining the Dataset Dict:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc44a7",
   "metadata": {},
   "source": [
    "Choosing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3246a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfbfbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = DatasetDict()\n",
    "\n",
    "raw_datasets['train'] = Dataset.from_pandas(train_df)\n",
    "raw_datasets['test'] = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de274a",
   "metadata": {},
   "source": [
    "### Defining a Pre-trained model as a class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abf57fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pre_trained_Model():\n",
    "    \n",
    "    def __init__(self, name, lr, lossFunc, dataset):\n",
    "        self.name = name\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.name, num_labels = 2)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.name)\n",
    "        self.dataset = dataset\n",
    "        self.tokenized_dataset = None\n",
    "        self.tokenized_test = None\n",
    "        self.lossFunc = lossFunc\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Trying different optimizers: Adam Selected!\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), self.lr)\n",
    "        #self.optimizer = torch.optim.Adagrad(self.model.parameters(), self.lr)\n",
    "        #self.optimizer = torch.optim.RMSprop(self.model.parameters(), self.lr)\n",
    "        #self.optimizer = torch.optim.SGD(self.model.parameters(), self.lr)\n",
    "\n",
    "        \n",
    "    def tokenize(self, parameters):\n",
    "        self.tokenized_dataset = self.dataset.map(self.tokenizer, input_columns='text', fn_kwargs = parameters)\n",
    "        for split in self.tokenized_dataset:\n",
    "                self.tokenized_dataset[split] = self.tokenized_dataset[split].add_column('labels',self.dataset[split]['labels'])\n",
    "                self.tokenized_dataset[split] = self.tokenized_dataset[split].remove_columns(['text'])\n",
    "        self.tokenized_dataset.set_format('torch')\n",
    "        \n",
    "        \n",
    "    def training(self, training_args):\n",
    "        trainer = Trainer( model = self.model, args = training_args, train_dataset = self.tokenized_dataset['train'],\n",
    "                      eval_dataset = self.tokenized_dataset['test'], compute_metrics = self.metrics)\n",
    "        trainer.train()\n",
    "\n",
    "    def predict(self, test_dataset):\n",
    "        trainer = Trainer(model = self.model, args = training_args, test_dataset = tokenized_test['test'], metrics = self.metrics)\n",
    "        \n",
    "\n",
    "        \n",
    "    def metrics(self, predictions):\n",
    "        # Calculating eval values: f1 score, accuracy, precision, recall\n",
    "        preds = predictions.predictions.argmax(axis = 1)\n",
    "        labels = predictions.label_ids\n",
    "        return {'f1': f1_score(preds, labels, average = 'binary'),\n",
    "                'accuracy':accuracy_score(preds, labels),\n",
    "                'precision_score': precision_score(preds, labels),\n",
    "                'recall_score': recall_score(preds, labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2074ef3",
   "metadata": {},
   "source": [
    "Trying different loss functions: BCE loss Selected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bd33b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.BCELoss()\n",
    "# loss_func = torch.nn.L1Loss()\n",
    "# loss_func = torch.nn.MSELoss()\n",
    "# loss_func = torch.nn.CosineEmbeddingLoss()\n",
    "# loss_func = torch.nn.CrossEntropyLoss()\n",
    "# loss_func = torch.nn.KLDivLoss()\n",
    "# loss_func = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f90fb",
   "metadata": {},
   "source": [
    "Defining the training arguments for the training (replace out path with a local path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e18fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = r\"D:/Users/ela86/Documents/\"\n",
    "args = TrainingArguments(output_dir = OUT_PATH,\n",
    "                         overwrite_output_dir = True,\n",
    "                         per_device_train_batch_size = 32,\n",
    "                         per_device_eval_batch_size = 32,\n",
    "                         learning_rate = 0.00001,\n",
    "                         weight_decay = 0.01,\n",
    "                         save_strategy = 'no',\n",
    "                         metric_for_best_model = 'dev_f1',\n",
    "                         greater_is_better = True,\n",
    "                         evaluation_strategy = 'epoch',\n",
    "                         do_train = True,\n",
    "                         num_train_epochs = 5,\n",
    "                         gradient_accumulation_steps = 5,\n",
    "                         fp16 = True,\n",
    "                         logging_strategy = 'epoch',\n",
    "                         report_to = 'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f50a0",
   "metadata": {},
   "source": [
    "## Defining Albert and Bert models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5f6e9",
   "metadata": {},
   "source": [
    "### Albert model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a11ce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.decoder.bias', 'predictions.bias', 'predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f669c95737eb413999254bee54313548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28125 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff02c533ec7400697f24135fd9ecb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9375 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 28125\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9375\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "model_name = 'albert-base-v2'\n",
    "model_albert = Pre_trained_Model(model_name, 0.00001, loss_func, raw_datasets)\n",
    "model_albert.tokenize({\"max_length\": 200, \"truncation\": True, \"padding\": \"max_length\"})\n",
    "model_albert.tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c5a8481",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 28125\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 160\n",
      "  Gradient Accumulation steps = 5\n",
      "  Total optimization steps = 875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 16:57, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.318558</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>0.870933</td>\n",
       "      <td>0.919127</td>\n",
       "      <td>0.837754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.284400</td>\n",
       "      <td>0.287625</td>\n",
       "      <td>0.876988</td>\n",
       "      <td>0.878720</td>\n",
       "      <td>0.867137</td>\n",
       "      <td>0.887065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.224500</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.877010</td>\n",
       "      <td>0.879253</td>\n",
       "      <td>0.863500</td>\n",
       "      <td>0.890949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.327066</td>\n",
       "      <td>0.872798</td>\n",
       "      <td>0.873707</td>\n",
       "      <td>0.869063</td>\n",
       "      <td>0.876565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.116100</td>\n",
       "      <td>0.357234</td>\n",
       "      <td>0.865624</td>\n",
       "      <td>0.865280</td>\n",
       "      <td>0.870347</td>\n",
       "      <td>0.860952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "model_albert.training(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0079e",
   "metadata": {},
   "source": [
    "### Bert model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0274f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\user/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\user/.cache\\huggingface\\transformers\\9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\user/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\user/.cache\\huggingface\\transformers\\0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at C:\\Users\\user/.cache\\huggingface\\transformers\\75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at C:\\Users\\user/.cache\\huggingface\\transformers\\8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\user/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ac5e3ecc144be4badaf22f69a0fee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28125 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d7baa8198143a4928a94802be83bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9375 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 28125\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9375\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "model_name2 = \"distilbert-base-uncased\"\n",
    "model_bert = Pre_trained_Model(model_name2, 0.001, loss_func, raw_datasets)\n",
    "model_bert.tokenize({\"max_length\": 200, \"truncation\": True, \"padding\": \"max_length\"})\n",
    "model_bert.tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aca61f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 28125\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 160\n",
      "  Gradient Accumulation steps = 5\n",
      "  Total optimization steps = 875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 06:40, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.438500</td>\n",
       "      <td>0.333266</td>\n",
       "      <td>0.864587</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>0.898160</td>\n",
       "      <td>0.833433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.319619</td>\n",
       "      <td>0.855982</td>\n",
       "      <td>0.863893</td>\n",
       "      <td>0.811297</td>\n",
       "      <td>0.905877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.272700</td>\n",
       "      <td>0.299958</td>\n",
       "      <td>0.878670</td>\n",
       "      <td>0.877013</td>\n",
       "      <td>0.893239</td>\n",
       "      <td>0.864568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.244400</td>\n",
       "      <td>0.293364</td>\n",
       "      <td>0.878244</td>\n",
       "      <td>0.879893</td>\n",
       "      <td>0.868849</td>\n",
       "      <td>0.887844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.294145</td>\n",
       "      <td>0.880919</td>\n",
       "      <td>0.881707</td>\n",
       "      <td>0.877621</td>\n",
       "      <td>0.884242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "model_bert.training(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "439fc211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  625258 KB |    7182 MB |  212112 GB |  212111 GB |\n",
      "|       from large pool |  623360 KB |    7177 MB |  212055 GB |  212054 GB |\n",
      "|       from small pool |    1898 KB |       4 MB |      57 GB |      57 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  625258 KB |    7182 MB |  212112 GB |  212111 GB |\n",
      "|       from large pool |  623360 KB |    7177 MB |  212055 GB |  212054 GB |\n",
      "|       from small pool |    1898 KB |       4 MB |      57 GB |      57 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    7872 MB |    7872 MB |    7872 MB |       0 B  |\n",
      "|       from large pool |    7866 MB |    7866 MB |    7866 MB |       0 B  |\n",
      "|       from small pool |       6 MB |       6 MB |       6 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  464278 KB |     851 MB |   74374 GB |   74374 GB |\n",
      "|       from large pool |  462080 KB |     849 MB |   74292 GB |   74292 GB |\n",
      "|       from small pool |    2198 KB |       2 MB |      82 GB |      82 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     265    |     702    |   12647 K  |   12647 K  |\n",
      "|       from large pool |      94    |     317    |    8455 K  |    8455 K  |\n",
      "|       from small pool |     171    |     411    |    4192 K  |    4192 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     265    |     702    |   12647 K  |   12647 K  |\n",
      "|       from large pool |      94    |     317    |    8455 K  |    8455 K  |\n",
      "|       from small pool |     171    |     411    |    4192 K  |    4192 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     154    |     154    |     154    |       0    |\n",
      "|       from large pool |     151    |     151    |     151    |       0    |\n",
      "|       from small pool |       3    |       3    |       3    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      59    |     144    |    6768 K  |    6768 K  |\n",
      "|       from large pool |      39    |     134    |    4773 K  |    4773 K  |\n",
      "|       from small pool |      20    |      32    |    1994 K  |    1994 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(abbreviated=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c966ffff",
   "metadata": {},
   "source": [
    "# Compression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5713020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model): # Checking the size of the model.\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d1d28",
   "metadata": {},
   "source": [
    "## 1) Prune - Albert model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe3b76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq_classification = model_albert.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11fba2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 46.755601\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model_seq_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2953886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(model, amount1, amount2): # The pruning function, pruning the layers of the model.\n",
    "    for name, module in model_seq_classification.named_parameters():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            prune.l1_unstructured(module, name = 'weight', amount = amount1)\n",
    "        # prune 40% of connections in all linear layers\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            prune.l1_unstructured(module, name = 'weight', amount = amount2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7b2d8",
   "metadata": {},
   "source": [
    "### first pruning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6745f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune(model_seq_classification, 0.35, 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ae4e14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 46.755601\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model_seq_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a295fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 28125\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 160\n",
      "  Gradient Accumulation steps = 5\n",
      "  Total optimization steps = 875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 16:56, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.366621</td>\n",
       "      <td>0.869556</td>\n",
       "      <td>0.864213</td>\n",
       "      <td>0.907788</td>\n",
       "      <td>0.834415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.431186</td>\n",
       "      <td>0.854958</td>\n",
       "      <td>0.858347</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.873271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.464223</td>\n",
       "      <td>0.868399</td>\n",
       "      <td>0.866027</td>\n",
       "      <td>0.886607</td>\n",
       "      <td>0.850924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.511997</td>\n",
       "      <td>0.863805</td>\n",
       "      <td>0.862933</td>\n",
       "      <td>0.871844</td>\n",
       "      <td>0.855913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.563145</td>\n",
       "      <td>0.859007</td>\n",
       "      <td>0.859413</td>\n",
       "      <td>0.859007</td>\n",
       "      <td>0.859007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training after first pruning:\n",
    "model_albert.training(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd52ac",
   "metadata": {},
   "source": [
    "### second pruning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0557beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune(model_seq_classification, 0.35, 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "241bcf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 46.755601\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model_seq_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9bdc5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 28125\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 160\n",
      "  Gradient Accumulation steps = 5\n",
      "  Total optimization steps = 875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 17:00, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.474268</td>\n",
       "      <td>0.869896</td>\n",
       "      <td>0.868480</td>\n",
       "      <td>0.881900</td>\n",
       "      <td>0.858214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.551341</td>\n",
       "      <td>0.858027</td>\n",
       "      <td>0.863040</td>\n",
       "      <td>0.830124</td>\n",
       "      <td>0.887872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.609081</td>\n",
       "      <td>0.862025</td>\n",
       "      <td>0.860480</td>\n",
       "      <td>0.874198</td>\n",
       "      <td>0.850187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.673225</td>\n",
       "      <td>0.859714</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.868635</td>\n",
       "      <td>0.850975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.715280</td>\n",
       "      <td>0.860346</td>\n",
       "      <td>0.860480</td>\n",
       "      <td>0.862003</td>\n",
       "      <td>0.858696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9375\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training after second pruning:\n",
    "model_albert.training(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a67db",
   "metadata": {},
   "source": [
    "## Prediction - Albert: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac40ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2987a25f",
   "metadata": {},
   "source": [
    "## 2) Quantization - Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00c11479",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq_classification = model_bert.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bfa0fddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 267.860529\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model_seq_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40f0c884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  (classifier): DynamicQuantizedLinear(in_features=768, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq_classification = model_bert.model\n",
    "model_seq_classification.to('cpu')\n",
    "quantization.quantize_dynamic(model_seq_classification, {torch.nn.Linear}, dtype = torch.qint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01658b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 267.859057\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model_seq_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "882ba955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq_classification.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84563807",
   "metadata": {},
   "source": [
    "## Predictiction - Bert: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9504a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
